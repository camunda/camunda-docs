{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1c5e4a94",
      "metadata": {
        "id": "1c5e4a94"
      },
      "source": [
        "# Clean and Extend `getlivebench_data` Notebook\n",
        "\n",
        "This notebook fetches and cleans LLM benchmark data for **per-model** and **per-task** analysis.  \n",
        "It uses the Artificial Analysis API (requires `AA_API_KEY`) and outputs:\n",
        "\n",
        "- `out/by_models.csv` – consolidated table (one row per model).\n",
        "\n",
        "### What’s improved\n",
        "- Adds **speed** & **latency** fields (e.g. `median_output_tokens_per_second`, `median_time_to_first_token_seconds`).\n",
        "- Adds **context window** (searches `context_window_tokens`, `context_window`, `max_context_tokens`).\n",
        "- **LIVEBENCH**: prefers **fine-grained subtask columns** and **drops aggregate indices** (Math/Coding/Intelligence).\n",
        "- Cleans incorrect price columns by robust numeric parsing and normalizing to **per‑1K tokens** when possible.\n",
        "- Removes columns with **all missing values**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "462b7390",
      "metadata": {
        "id": "462b7390"
      },
      "source": [
        "## 1) Prereqs & Config\n",
        "\n",
        "Set `AA_API_KEY` in your environment. You can do this in the notebook session:\n",
        "```python\n",
        "import os\n",
        "os.environ[\"AA_API_KEY\"] = \"YOUR_KEY_HERE\"\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08c434bb",
      "metadata": {
        "id": "08c434bb"
      },
      "outputs": [],
      "source": [
        "# Imports & constants\n",
        "import os, math, re, json, pathlib, unicodedata\n",
        "from typing import Any, Dict, List, Tuple\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "BASE = \"https://artificialanalysis.ai\"\n",
        "API  = f\"{BASE}/api/v2/data/llms/models\"  # documented free API endpoint\n",
        "\n",
        "OUT_DIR = pathlib.Path(\"out\")\n",
        "\n",
        "def to_float(x):\n",
        "    try:\n",
        "        if x is None:\n",
        "            return None\n",
        "        if isinstance(x, (int, float)):\n",
        "            return float(x)\n",
        "        # Strip common symbols\n",
        "        s = str(x).strip().replace(\"$\",\"\").replace(\",\",\"\")\n",
        "        return float(s) if s not in {\"\", \"None\", \"nan\"} else None\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def first_not_none(*vals):\n",
        "    for v in vals:\n",
        "        if v is not None:\n",
        "            return v\n",
        "    return None\n",
        "\n",
        "def slugify(text: str) -> str:\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('ascii')\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\-_. ]+', '', text)\n",
        "    text = text.strip().lower().replace(' ', '-')\n",
        "    text = re.sub(r'-{2,}', '-', text)\n",
        "    return text or \"model\"\n",
        "\n",
        "def fetch_models() -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:\n",
        "    key = os.getenv(\"AA_API_KEY\")\n",
        "    if not key:\n",
        "        raise SystemExit(\"Set AA_API_KEY (required by Artificial Analysis free API).\")\n",
        "    r = requests.get(API, headers={\"x-api-key\": key}, timeout=60)\n",
        "    r.raise_for_status()\n",
        "    payload = r.json()\n",
        "    data = payload.get(\"data\", [])\n",
        "    meta = {k: v for k, v in payload.items() if k != \"data\"}\n",
        "    return data, meta\n",
        "\n",
        "# Columns we consider \"aggregate indices\" and want to DROP in favor of their subtasks\n",
        "AGGREGATE_KEYS = {\n",
        "    \"artificial_analysis_intelligence_index\",\n",
        "    \"artificial_analysis_math_index\",\n",
        "    \"artificial_analysis_coding_index\",\n",
        "    \"aa_intelligence_index\",\n",
        "    \"aa_math_index\",\n",
        "    \"aa_coding_index\",\n",
        "    \"livebench_overall\",\n",
        "    \"livebench_aggregate\",\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f37eeb9d",
      "metadata": {
        "id": "f37eeb9d"
      },
      "source": [
        "## 2) Fetch data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8ee229d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8ee229d",
        "outputId": "721ddfcb-f1f2-4286-d351-b1090789ee96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(269, ['status', 'prompt_options'])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_models, meta = fetch_models()\n",
        "len(raw_models), list(meta.keys())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a7cabef",
      "metadata": {
        "id": "7a7cabef"
      },
      "source": [
        "## 3) Normalize & Flatten\n",
        "\n",
        "- Extract core identity & provider fields.\n",
        "- Normalize **pricing** and compute per‑1K estimates when possible.\n",
        "- Retain **speed/latency** and **context window**.\n",
        "- Expand **evaluation** tasks into flat columns (drop aggregates).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "421bda2f",
      "metadata": {
        "id": "421bda2f"
      },
      "outputs": [],
      "source": [
        "records = []\n",
        "\n",
        "for m in raw_models:\n",
        "    mid   = m.get(\"id\") or m.get(\"model_id\") or m.get(\"uid\")\n",
        "    name  = m.get(\"name\") or m.get(\"model_name\")\n",
        "    prov_obj = m.get(\"provider\") or m.get(\"organization\")\n",
        "    if isinstance(prov_obj, dict):\n",
        "        prov = prov_obj.get(\"name\")\n",
        "    else:\n",
        "        prov = prov_obj\n",
        "    family= m.get(\"family\") or m.get(\"series\")\n",
        "\n",
        "    # Speed & latency (various possible keys)\n",
        "    tps   = first_not_none(\n",
        "        m.get(\"median_output_tokens_per_second\"),\n",
        "        m.get(\"output_tokens_per_second\"),\n",
        "        m.get(\"median_tokens_per_second\"),\n",
        "        m.get(\"tokens_per_second\"),\n",
        "    )\n",
        "    ttf   = first_not_none(\n",
        "        m.get(\"median_time_to_first_token_seconds\"),\n",
        "        m.get(\"median_ttfb_seconds\"),\n",
        "        m.get(\"time_to_first_token_seconds\"),\n",
        "        m.get(\"ttft_seconds\"),\n",
        "    )\n",
        "    tta   = first_not_none(\n",
        "        m.get(\"median_time_to_first_answer_token\"),\n",
        "        m.get(\"time_to_first_answer_token_seconds\"),\n",
        "        m.get(\"ttfa_seconds\"),\n",
        "    )\n",
        "\n",
        "    # Context window\n",
        "    ctx   = first_not_none(\n",
        "        m.get(\"context_window_tokens\"),\n",
        "        m.get(\"context_window\"),\n",
        "        m.get(\"max_context_tokens\"),\n",
        "        m.get(\"max_input_tokens\"),\n",
        "    )\n",
        "\n",
        "    # Pricing (attempt to find numbers; normalize to per-1K if we detect per‑million)\n",
        "    pricing = m.get(\"pricing\") or m.get(\"prices\") or {}\n",
        "    if isinstance(pricing, dict):\n",
        "        inp = to_float(pricing.get(\"input\", pricing.get(\"prompt\")))\n",
        "        outp= to_float(pricing.get(\"output\", pricing.get(\"completion\")))\n",
        "        # normalize to per-1K\n",
        "        def normalize_per_1k(v):\n",
        "            if v is None:\n",
        "                return None\n",
        "            # Heuristic: if >= 0.5, likely per-1M; divide by 1000. Otherwise keep.\n",
        "            return v/1000.0 if v >= 0.5 else v\n",
        "        price_in_per1k  = normalize_per_1k(inp) if inp is not None else None\n",
        "        price_out_per1k = normalize_per_1k(outp) if outp is not None else None\n",
        "    else:\n",
        "        price_in_per1k = price_out_per1k = None\n",
        "\n",
        "    base = {\n",
        "        \"model_id\": mid,\n",
        "        \"model_name\": name,\n",
        "        \"provider\": prov,\n",
        "        \"family\": family,\n",
        "        \"median_output_tokens_per_second\": to_float(tps),\n",
        "        \"median_time_to_first_token_seconds\": to_float(ttf),\n",
        "        \"median_time_to_first_answer_token\": to_float(tta),\n",
        "        \"context_window_tokens\": to_float(ctx),\n",
        "        \"price_input_per_1k\": to_float(price_in_per1k),\n",
        "        \"price_output_per_1k\": to_float(price_out_per1k),\n",
        "    }\n",
        "\n",
        "    # Evaluations -> flatten as columns\n",
        "    evals = m.get(\"evaluations\") or m.get(\"evals\") or {}\n",
        "    flat = {}\n",
        "    if isinstance(evals, dict):\n",
        "        for task, val in evals.items():\n",
        "            # Skip aggregates\n",
        "            if task in AGGREGATE_KEYS:\n",
        "                continue\n",
        "            # Value can be a dict like {\"score\": 0.55, ...} or a direct number\n",
        "            if isinstance(val, dict):\n",
        "                score = val.get(\"score\")\n",
        "                flat[str(task)] = to_float(score)\n",
        "            else:\n",
        "                flat[str(task)] = to_float(val)\n",
        "\n",
        "    rec = {**base, **flat}\n",
        "    records.append(rec)\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.DataFrame.from_records(records)\n",
        "\n",
        "# Drop columns that are entirely missing\n",
        "df = df.dropna(axis=1, how=\"all\")\n",
        "\n",
        "# Ensure numeric type for all evaluation columns (leave id/name/provider as is)\n",
        "non_eval_cols = {\"model_id\",\"model_name\",\"provider\",\"family\"}\n",
        "for c in df.columns:\n",
        "    if c not in non_eval_cols:\n",
        "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "print(df)\n",
        "\n",
        "\n",
        "# Sort models by a reasonable default (e.g., tokens/sec desc then context desc)\n",
        "df = df.sort_values(\n",
        "    by=[\"median_output_tokens_per_second\",\"context_window_tokens\"],\n",
        "    ascending=[False, False]\n",
        ").reset_index(drop=True)\n",
        "\n",
        "df.head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15ff0cc9",
      "metadata": {
        "id": "15ff0cc9"
      },
      "source": [
        "## 4) Save consolidated CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec46bc6b",
      "metadata": {
        "id": "ec46bc6b"
      },
      "outputs": [],
      "source": [
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "by_models_path = OUT_DIR / \"by_models.csv\"\n",
        "df.to_csv(by_models_path, index=False)\n",
        "print(f\"Saved: {by_models_path.resolve()}\")\n",
        "print(f\"Columns: {len(df.columns)}  |  Models: {len(df)}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Clean_and_Extend_getlivebench_data.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
